{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(\"/workspaces/OmicsCopilot/src/server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "import data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[-3.3973e-02, -5.6586e-04,  3.1019e-02, -2.4794e-02, -1.4177e-02,\n",
      "         -2.3554e-02,  3.8484e-02,  3.4079e-02,  5.4125e-02, -2.4609e-02,\n",
      "         -1.7066e-02, -9.3637e-04, -1.2509e-02, -3.1339e-03,  4.5843e-02,\n",
      "          2.2921e-02, -2.8289e-03, -6.9041e-03, -6.2671e-02,  1.0874e-02,\n",
      "          8.1873e-02,  4.2244e-04, -1.5589e-02,  2.4227e-02, -2.8118e-02,\n",
      "          5.4896e-03,  8.2625e-03, -1.1408e-02,  3.1810e-02, -5.2701e-02,\n",
      "         -2.9779e-02, -1.1553e-02, -6.4227e-03,  1.5681e-02,  2.8830e-02,\n",
      "          3.2654e-02, -6.8263e-02,  1.7395e-02, -8.2453e-02,  1.7053e-02,\n",
      "          4.5368e-02,  2.6865e-02, -3.6795e-03,  2.8645e-02, -1.2727e-02,\n",
      "         -2.6733e-02, -3.5081e-02, -3.4105e-02,  1.3175e-02, -3.1362e-02,\n",
      "         -1.9585e-02, -1.2272e-02, -3.9532e-03, -6.9001e-02,  1.6568e-03,\n",
      "          5.0986e-02,  4.8454e-02,  2.8381e-02,  1.8609e-02,  1.1230e-02,\n",
      "          5.2595e-02, -1.1500e-02, -1.6438e-01,  5.2424e-03,  2.2789e-02,\n",
      "          4.9615e-02, -2.5269e-02,  1.6288e-02,  7.7481e-03,  4.1754e-02,\n",
      "          1.2054e-02, -2.0798e-02,  4.5104e-02,  9.9546e-02, -9.2740e-02,\n",
      "          1.1025e-02,  1.1388e-02,  3.0597e-03, -2.9885e-02, -7.1217e-03,\n",
      "          7.4118e-03,  1.1355e-02,  1.5866e-02,  1.7620e-02, -5.8873e-02,\n",
      "         -3.0808e-02, -1.2298e-02,  2.3251e-02,  6.3357e-02, -5.5984e-03,\n",
      "         -2.5453e-02, -5.1804e-02, -1.2430e-02,  1.5668e-02, -3.6347e-02,\n",
      "         -4.4999e-02,  3.1863e-02, -2.3291e-02,  3.2232e-02,  3.3636e-01,\n",
      "         -1.1513e-02,  3.4026e-02,  2.8381e-02, -9.7646e-02,  1.4639e-02,\n",
      "         -1.2239e-02,  4.4840e-02, -4.6397e-02, -2.2222e-02, -2.0218e-02,\n",
      "         -6.8263e-02,  1.4481e-02,  3.2153e-02, -7.6360e-03,  8.5460e-03,\n",
      "         -3.8932e-02,  4.6845e-02,  5.5325e-03, -2.9832e-02, -1.6274e-02,\n",
      "          2.5374e-02, -9.7066e-03, -3.6927e-02, -1.5760e-02,  1.8042e-02,\n",
      "         -3.0702e-02,  6.9318e-02,  5.6604e-02,  5.1224e-02, -5.6380e-03,\n",
      "          5.3334e-02, -3.5609e-02, -6.6140e-03,  4.9773e-02, -4.9166e-02,\n",
      "         -2.6680e-02,  1.4797e-02,  3.8246e-02,  1.8239e-02, -2.9595e-02,\n",
      "         -1.5087e-02, -1.0762e-01, -6.4570e-02, -5.3307e-02, -5.0828e-02,\n",
      "          9.9968e-02, -2.4082e-02,  1.8332e-02, -1.5430e-02, -2.2486e-02,\n",
      "          3.0808e-02,  3.8985e-02,  2.9964e-02, -4.1200e-02,  1.9400e-02,\n",
      "          5.0617e-02,  3.4422e-02, -8.8823e-03,  1.3452e-02,  5.1646e-02,\n",
      "          3.5661e-02, -2.4966e-02, -2.6588e-02,  8.1715e-02,  1.5852e-02,\n",
      "         -1.0962e-01, -3.7620e-03, -2.7854e-02,  5.6130e-02, -6.9832e-03,\n",
      "          5.9295e-02,  3.9117e-02, -2.6390e-02,  2.4715e-02,  1.6591e-02,\n",
      "          6.6364e-02, -1.4771e-02, -3.1092e-03, -5.8128e-03,  3.1969e-02,\n",
      "          3.8826e-02, -3.6532e-02, -7.9869e-02,  6.9476e-02,  7.9658e-03,\n",
      "         -2.0943e-02, -5.9471e-04, -3.6189e-02,  4.2836e-02, -1.4507e-02,\n",
      "         -3.6875e-02,  1.0176e-01,  3.1520e-03,  5.1764e-03, -8.4564e-02,\n",
      "          4.4511e-03,  3.6294e-02, -7.1428e-02, -2.1405e-02, -2.0745e-02,\n",
      "         -2.2842e-02,  2.0310e-02, -1.5958e-02, -6.1458e-03,  2.4346e-02,\n",
      "         -8.3548e-03,  1.3874e-02, -1.3966e-02,  4.1121e-02, -1.3755e-02,\n",
      "         -5.0459e-02, -3.5556e-02, -1.7771e-03,  5.5444e-02,  2.2140e-03,\n",
      "         -8.0660e-02, -3.9934e-02,  3.8352e-02,  2.5572e-02,  1.5628e-02,\n",
      "         -1.0867e-02, -2.1589e-02,  4.5975e-02, -3.5535e-01, -3.1230e-02,\n",
      "          2.4201e-02, -4.3759e-02,  4.3970e-02, -7.6822e-03,  1.5852e-02,\n",
      "         -2.2895e-02, -1.8226e-02,  3.4751e-03,  1.7145e-02, -1.0683e-01,\n",
      "          7.4540e-02, -2.1774e-02,  3.3287e-02,  7.1019e-03, -2.5493e-02,\n",
      "         -1.4639e-03,  9.0314e-02,  3.6822e-02,  5.3967e-02, -3.1362e-02,\n",
      "          1.3518e-02, -5.7712e-02,  4.5843e-02, -6.4788e-04,  1.9297e-01,\n",
      "          9.8068e-02, -2.0033e-02, -3.5002e-02,  3.1256e-02, -3.2760e-02,\n",
      "          1.2331e-02, -9.4481e-02,  8.2955e-03,  1.9980e-02, -2.1444e-02,\n",
      "          3.2610e-05, -2.0904e-02,  1.0656e-02, -7.6295e-03,  6.2565e-02,\n",
      "         -2.1233e-02,  1.5114e-02, -1.8978e-02, -4.8955e-02, -4.9430e-02,\n",
      "         -1.6116e-02, -6.0825e-02,  6.2671e-02,  7.1217e-03, -2.9542e-02,\n",
      "         -1.4824e-02,  1.4995e-02,  4.8586e-02, -3.2048e-02, -5.7923e-02,\n",
      "         -5.2173e-02, -3.2839e-02, -7.3657e-03, -6.0370e-03,  6.3515e-02,\n",
      "          3.8879e-02,  4.3357e-03,  4.8612e-02,  4.0831e-02,  4.8981e-02,\n",
      "         -8.7940e-02, -4.5843e-02,  5.9822e-02, -4.1042e-02,  6.3357e-02,\n",
      "         -6.5150e-03, -8.4880e-02,  3.6598e-03, -7.0162e-03, -1.7329e-02,\n",
      "         -2.6654e-02, -2.9252e-02, -2.7880e-02,  3.5397e-02,  3.3235e-02,\n",
      "         -1.9057e-02,  2.0785e-02,  6.2354e-02,  5.3782e-02,  2.3488e-02,\n",
      "         -8.5131e-03,  6.6680e-02, -2.1180e-02, -2.2025e-02, -1.1804e-02,\n",
      "         -1.3571e-02,  2.5008e-03, -2.3805e-03, -4.5684e-02, -3.0386e-01,\n",
      "          3.4817e-02, -5.7633e-03,  3.1230e-02,  1.3116e-02,  5.8925e-02,\n",
      "         -5.1039e-02,  1.3808e-02, -4.9351e-02,  1.2819e-02, -4.1121e-02,\n",
      "          3.4791e-02,  3.0122e-02, -1.0597e-02, -3.8668e-02,  2.9647e-02,\n",
      "          4.1807e-02, -1.7712e-02,  3.9169e-02, -8.9892e-02,  3.0623e-02,\n",
      "          6.4920e-03,  1.2756e-01, -5.2674e-02,  9.4956e-02,  1.5509e-02,\n",
      "         -3.9354e-02, -2.8434e-02,  4.7346e-02,  3.0966e-02,  4.0066e-02,\n",
      "         -1.7132e-02,  8.3772e-02,  4.3152e-02,  1.3597e-02, -5.2041e-02,\n",
      "          2.4952e-02,  1.8305e-02,  2.1365e-02,  2.3871e-02, -6.5836e-02,\n",
      "          3.0650e-02, -8.1768e-02,  1.0214e-02,  9.1738e-02,  2.4121e-02,\n",
      "          6.2038e-02, -8.1082e-02, -5.8556e-02, -9.6209e-03,  1.3478e-02,\n",
      "         -1.7422e-02,  1.6248e-02,  4.9094e-03,  4.3495e-02, -4.3620e-03,\n",
      "         -2.7142e-02, -4.6476e-02, -3.4685e-03, -3.3314e-02, -2.2051e-02,\n",
      "         -3.6532e-02,  1.8266e-02,  3.4870e-02,  1.3406e-02],\n",
      "        [-1.5780e-02,  1.6596e-02, -1.4069e-02,  1.7965e-02, -1.7149e-02,\n",
      "         -2.6415e-02,  3.7009e-02,  2.8934e-04,  6.4174e-02,  8.4495e-03,\n",
      "         -4.4274e-02,  1.3010e-02,  7.2176e-02, -4.2827e-02,  6.4648e-02,\n",
      "          3.5825e-02, -3.3133e-03, -1.9742e-02, -5.6330e-02, -1.2082e-02,\n",
      "          3.0323e-02, -1.4161e-02,  2.8534e-02,  5.6495e-03, -1.7320e-02,\n",
      "          4.4564e-02, -7.1268e-03, -3.2219e-02, -3.7799e-02, -1.6794e-01,\n",
      "          4.9026e-03, -3.9220e-02,  1.8873e-02,  3.1034e-02,  2.7902e-02,\n",
      "          2.2940e-02, -8.8075e-02,  4.6407e-02, -4.4538e-02,  2.7270e-02,\n",
      "          3.9589e-02,  4.3116e-02, -7.2453e-03, -4.1458e-02,  1.5728e-02,\n",
      "         -4.0247e-02, -6.2753e-02,  4.2274e-02,  6.7386e-02,  5.9193e-03,\n",
      "         -7.0965e-02, -3.3982e-02, -6.5601e-04,  1.1325e-02,  3.2482e-02,\n",
      "          2.8902e-02, -2.5862e-03,  1.0113e-01,  4.8512e-02, -3.4647e-03,\n",
      "          2.3322e-02,  7.4756e-02, -1.8068e-01,  5.0592e-02, -2.1440e-02,\n",
      "         -2.1611e-02,  8.6864e-04,  1.8327e-03, -3.2535e-02,  5.8857e-02,\n",
      "         -7.0018e-03, -5.3435e-02,  4.1668e-02,  4.6775e-02,  2.3937e-03,\n",
      "          5.5812e-04, -3.3403e-02, -2.6007e-02, -1.3806e-02,  3.0876e-02,\n",
      "          4.3248e-02, -4.7380e-02, -1.2457e-02,  1.5061e-03, -1.8676e-02,\n",
      "         -3.5799e-02, -2.1479e-02,  1.5938e-02,  1.1819e-02,  2.2729e-02,\n",
      "         -5.1724e-02, -4.6907e-02, -6.5740e-03,  6.1298e-03, -5.3673e-04,\n",
      "         -5.3145e-02, -2.3901e-02,  2.9771e-02,  7.2597e-02,  3.5756e-01,\n",
      "         -1.7570e-02,  2.4006e-02,  7.5809e-02, -6.8754e-02, -1.1463e-02,\n",
      "         -6.1068e-03,  3.7115e-02, -1.8492e-02, -3.1587e-02,  5.5014e-02,\n",
      "         -6.8333e-02, -4.4880e-02,  3.3008e-02, -7.5085e-03,  6.4161e-03,\n",
      "          3.2689e-03,  3.9010e-02,  8.5022e-03, -8.5351e-03,  8.8641e-03,\n",
      "          6.6530e-03,  4.5696e-02, -7.5282e-02, -3.8760e-03,  3.4061e-02,\n",
      "         -4.5433e-02,  4.9697e-02,  8.1494e-02,  6.4332e-02,  1.1138e-03,\n",
      "          4.0747e-02,  6.3069e-02, -4.6670e-02,  1.6070e-02,  1.0950e-02,\n",
      "         -3.5430e-02,  3.9958e-02, -3.1508e-02,  5.9436e-02, -2.4835e-02,\n",
      "          1.7123e-02, -2.4598e-02, -2.1466e-02,  1.0052e-03, -3.7641e-02,\n",
      "          1.4509e-01, -5.7594e-02, -3.0429e-02, -1.1562e-02, -1.0588e-02,\n",
      "         -2.0874e-02,  6.3595e-02,  4.4617e-02, -9.7709e-02, -2.1242e-02,\n",
      "          1.9321e-02,  3.2271e-02, -4.1484e-02, -4.1458e-02, -1.7866e-03,\n",
      "          5.2276e-02,  3.7852e-02, -2.0795e-02,  8.3074e-02,  4.6538e-02,\n",
      "         -2.4243e-02, -1.1023e-02, -3.8233e-03, -9.5090e-03, -6.2332e-02,\n",
      "          5.7284e-03,  2.7515e-04, -7.8757e-02,  2.8349e-02,  2.9560e-02,\n",
      "         -3.9056e-03, -2.1900e-02, -5.0513e-02,  3.4298e-02,  5.7679e-03,\n",
      "          6.9807e-02, -2.1505e-02, -6.8281e-02,  5.1487e-02, -5.7120e-03,\n",
      "         -1.3345e-02, -5.3882e-02, -2.5941e-02,  1.3675e-02,  9.7327e-03,\n",
      "         -8.8970e-03,  5.9647e-02, -2.5638e-02, -3.6983e-02, -5.4066e-02,\n",
      "         -4.9723e-02,  2.1598e-02,  6.0904e-03, -4.5459e-02,  7.0347e-03,\n",
      "          1.1753e-02, -1.2582e-02, -7.4493e-02, -4.7144e-02,  6.3385e-02,\n",
      "         -5.6593e-02, -1.6794e-02,  8.0218e-03,  5.7594e-02,  8.1863e-02,\n",
      "         -1.2536e-02, -2.0466e-02,  3.9484e-02,  2.4217e-02, -2.5730e-02,\n",
      "         -5.7067e-02, -2.9350e-02,  2.8455e-02,  4.3774e-02,  1.1240e-02,\n",
      "         -2.6507e-02, -2.5243e-02, -8.6535e-03, -3.1145e-01, -7.7980e-03,\n",
      "          7.7072e-02, -2.3243e-02,  6.1173e-02, -9.0154e-03, -4.1326e-03,\n",
      "         -7.4164e-03,  5.8067e-02,  1.8702e-02, -1.4428e-03, -5.4751e-02,\n",
      "          1.3174e-02, -2.9034e-02,  3.0139e-03,  1.0707e-02, -2.8534e-02,\n",
      "          8.1494e-02,  4.8499e-03,  1.4648e-02,  3.6141e-02, -6.7715e-03,\n",
      "          4.0247e-02, -9.9604e-02, -3.3061e-02,  3.8826e-03,  1.7268e-01,\n",
      "          8.3284e-02,  3.9194e-02,  1.9650e-02,  4.0747e-02, -3.1271e-02,\n",
      "         -1.0226e-02, -9.6814e-02,  8.0231e-02,  3.3035e-02,  4.0931e-02,\n",
      "          1.2273e-03, -2.3940e-02,  2.9432e-03,  5.4014e-02,  4.5959e-02,\n",
      "          9.2869e-04, -4.1010e-02, -6.7017e-02, -6.4918e-03, -3.9168e-02,\n",
      "         -5.7436e-02, -2.7586e-02,  1.4122e-02,  2.0321e-02, -4.2590e-02,\n",
      "          3.7036e-02, -2.8346e-03,  1.2299e-02, -5.1329e-02, -5.5593e-02,\n",
      "         -2.2242e-02, -2.2703e-02, -3.0982e-02, -7.0544e-03,  6.5701e-02,\n",
      "         -2.2558e-02, -1.0970e-02,  4.7380e-03,  4.9434e-02,  6.2648e-02,\n",
      "         -2.2756e-02,  7.1597e-03,  7.7915e-03, -2.9876e-02,  1.8900e-02,\n",
      "         -3.1113e-02, -2.0189e-02,  1.0833e-03,  3.1403e-02, -8.5443e-02,\n",
      "          2.1677e-02, -5.5383e-02, -2.1584e-02,  5.8173e-02,  6.0542e-03,\n",
      "          7.2584e-03,  1.2470e-03,  3.1482e-02,  3.5351e-02,  3.1166e-02,\n",
      "         -1.4122e-02, -1.3161e-03,  1.8584e-02,  4.1853e-02,  2.9613e-02,\n",
      "         -2.0308e-02, -8.4561e-03,  1.9123e-02, -1.6952e-02, -2.9650e-01,\n",
      "         -3.3535e-02, -2.9323e-02,  7.7520e-03,  4.1405e-02,  4.6170e-02,\n",
      "         -1.2141e-02,  4.5775e-02, -6.5490e-02,  3.4904e-02, -4.1879e-02,\n",
      "          5.9805e-02, -1.4398e-02, -2.6717e-02,  1.6534e-03,  2.0742e-02,\n",
      "          9.9236e-02,  1.0733e-02,  3.5772e-02, -3.5772e-02,  9.6867e-03,\n",
      "          1.4227e-02,  1.6657e-01,  1.0220e-02,  2.2085e-02, -2.7928e-02,\n",
      "          1.4188e-02, -1.9400e-02,  2.8086e-02, -4.0175e-03, -5.8041e-03,\n",
      "         -5.8225e-02,  5.7330e-02,  2.3703e-02, -1.4385e-02,  2.6388e-03,\n",
      "         -2.5033e-02,  1.3063e-02,  1.7873e-02, -3.9484e-03, -4.6907e-02,\n",
      "          6.7780e-03, -2.3914e-02, -5.8962e-02,  8.0231e-02, -2.3269e-02,\n",
      "          2.6875e-02, -6.4648e-02, -5.6225e-02, -9.6274e-03,  3.3989e-03,\n",
      "          3.7641e-03,  1.5188e-02, -5.1829e-02,  6.5181e-03,  4.9907e-02,\n",
      "         -5.0013e-02, -1.5991e-02,  3.4167e-02,  5.8962e-03, -3.3351e-02,\n",
      "         -3.5272e-02, -6.1726e-03,  6.3069e-02, -3.3272e-02]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 13:18:32.575404481 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2023-11-26 13:18:32.575419138 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n"
     ]
    }
   ],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('models/BAAI/bge-small-en-v1.5-onnx-O4')\n",
    "ort_model = ORTModelForFeatureExtraction.from_pretrained('models/BAAI/bge-small-en-v1.5-onnx-O4', provider=\"CUDAExecutionProvider\")\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt').to(\"cuda\")\n",
    "\n",
    "# Compute token embeddings\n",
    "model_output = ort_model(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, cls pooling.\n",
    "sentence_embeddings = model_output[0][:, 0]\n",
    "\n",
    "# normalize embeddings\n",
    "sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 13:18:41.629139453 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2023-11-26 13:18:41.629151961 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = pipeline(\n",
    "    'feature-extraction', \n",
    "    model=ort_model, \n",
    "    tokenizer=tokenizer, \n",
    "    device=0,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=True,\n",
    "    framework=\"pt\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# extractor(sentences) -> need CLS pooling\n",
    "extractor(sentences[0])[:, 0].numpy() == model_output[0][0, 0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = data.load.load_test_sentences()\n",
    "\n",
    "class Node(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    embedding: Optional[list] = None\n",
    "    author: str\n",
    "    year: int\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "\n",
    "def generator():\n",
    "    for x in data.load.load_test_sentences():\n",
    "        yield Node(**x)\n",
    "\n",
    "ds = KeyDataset(generator(), \"description\")\n",
    "\n",
    "# nodes \n",
    "\n",
    "# for d in generator():\n",
    "#     print(d)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/OmicsCopilot/notebooks/onnx-embeddings.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f74222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/OmicsCopilot/notebooks/onnx-embeddings.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m ds:\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f74222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/OmicsCopilot/notebooks/onnx-embeddings.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(x)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f74222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f6d7561646469622f7369657463682f4f6d696373436f70696c6f742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/OmicsCopilot/notebooks/onnx-embeddings.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py:305\u001b[0m, in \u001b[0;36mKeyDataset.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, i):\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[i][\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for x in ds:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: stuff to look into\n",
    "#     - implementing cls and mean pooling -> what is the difference?\n",
    "#       - which works better?\n",
    "#     - how to use the pipeline to get the embeddings\n",
    "#     - figure out best way to get embeddings for a set of Node objects, \n",
    "#       - need to be able to update the Node object with the embeddings\n",
    "#       - Node.upsert_embedding(db) -> store in db??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
